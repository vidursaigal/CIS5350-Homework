{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Set - III"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each Question/subquestion is worth **5 points**, unless indicated otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENCODE: Testing for Enrichment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to learn about possible genetic mechanisms of Alzheimer's using ENCODE data.\n",
    "\n",
    "SNPs associated with this disease can be found in `ALZ_SNPs_hg38.bed`.\n",
    "\n",
    "Choose an ENCODE data set from the ENCODE website that you think may be relevant to the disease (note: feel free to choose a tissue other than brain...there could be other tissues linked to the disease as well). Think both about tissue-type and ENCODE mark. Please do not use DNAse hypersensitivity or RNA-seq datasets. \n",
    "\n",
    "**Hint: it will be easiest if you find a data set with data in the bed file format.**\n",
    "\n",
    "**Note: Make sure the coordinates of the file you pick also use the hg38 reference genome**\n",
    "\n",
    "**Note: PLEASE try to pick a file size that is Less than 1 Gb -- this will make it run faster/Feasibly on CoCalc!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.** (2 points) What dataset did you choose and why? Include the tissue, epigenetic mark tested, and any identifying information, such as the name of the sample."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Dataset Chosen: Experiment summary for ENCSR872YGQ\n",
    "\t•\tAssay Type: Histone ChIP-seq\n",
    "\t•\tEpigenetic Mark: H3K27ac (associated with active enhancers and promoters)\n",
    "\t•\tTissue: Dorsolateral prefrontal cortex (Middle frontal area 46) from a female adult (89 years old) with Alzheimer’s disease\n",
    "\t•\tPlatform: Illumina NextSeq 500\n",
    "\t•\tProject: ENCODE4 (Bradley Bernstein Lab, Broad Institute)\n",
    "\n",
    "Why This Dataset?\n",
    "\t1.\tRelevance to Disease: The dorsolateral prefrontal cortex is a critical brain region for cognitive functions, heavily affected in Alzheimer’s disease. Examining histone modifications in this area can reveal transcriptional activity linked to disease pathology.\n",
    "\t2.\tEpigenetic Insight: The H3K27ac mark is essential for identifying active regulatory elements, such as enhancers and promoters, which may contribute to altered gene expression in Alzheimer’s disease.\n",
    "\t3.\tSpecificity and Quality: The dataset is highly specific to Alzheimer’s disease, and the ENCODE project ensures high-quality, standardized data. This experiment is unreplicated but uses rigorous ENCODE methodologies, enhancing confidence in the findings.\n",
    "\t4.\tData Compatibility: The dataset provides a BED narrowPeak file (hg38), which is compatible with the SNP analysis for Alzheimer’s disease (also in hg38 format).\n",
    "\n",
    "This dataset is ideal for identifying active genomic regions potentially linked to Alzheimer’s disease mechanisms, helping to pinpoint regulatory elements influenced by genetic variants associated with the condition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2:** (5 points) Now, test for significant overlap bewtween the Alzheimer's SNPs and your ENCODE mark. This time, instead of generating fake SNP sets, use the fisher exact test implemented in bedtools (http://bedtools.readthedocs.org/en/latest/content/tools/fisher.html). \n",
    "\n",
    "**NOTE: The fisher tool requires that your data is pre-sorted by chromosome and then by start position. e.g.**\n",
    "\n",
    "```bash\n",
    "$ sort -k1,1 -k2,2n in.bed > in.sorted.bed \n",
    "```\n",
    "    \n",
    "**for BED files, where `in.bed` is your input bed file and `in.sorted.bed` is the name that you want for the sorted output.**\n",
    "\n",
    "This test looks for an association between two classifications. In our case, we are looking for an association between being a SNP in ALZ_SNPs_hg38.bed and being in an interval from your ENCODE data set. Run this test on your datasets. \n",
    "\n",
    "**NOTE: We have provided you a pre-sorted genome file in this directory that you can use for this analysis (human.hg38.genome).**\n",
    "\n",
    "What is the two-tailed p-value? This is the p-value that under the null hypothesis (random chance), the given parameter (probability of overlap) is more extreme than what we observe in our data. Please include your unix commands in the top box and your answer in the bottom box."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "sort -k1,1 -k2,2n ENCFF983DQA.bed > ENCFF983DQA.sorted.bed\n",
    "sort -k1,1 -k2,2n AD_SNPs_hg38.bed > ALZ_SNPs_hg38.sorted.bed\n",
    "bedtools fisher -a ALZ_SNPs_hg38.sorted.bed -b ENCFF983DQA.sorted.bed -g human.hg38.genome"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "The two-tailed p-value is 2.874e-163.\n",
    "\n",
    "This extremely small value indicates that the observed overlap between Alzheimer’s-associated SNPs and H3K27ac-marked regions in the dorsolateral prefrontal cortex is highly statistically significant and is not due to random chance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3.** (5 points)  Was there a significant association between the disease-associated genetic variants and the ENCODE mark? Explain your findings to the best of your abilities. Are you suprised by the result? If so, why? If not, why not?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Yes, there was a significant association between the disease-associated genetic variants (SNPs from Alzheimer’s-associated regions) and the ENCODE mark (H3K27ac in the dorsolateral prefrontal cortex). The results from the Fisher’s exact test indicate an extremely small two-tailed p-value of 2.874e-163, and the enrichment ratio of 3.875 shows that the SNPs are almost 4 times more likely to fall within H3K27ac-marked regions than expected by random chance.\n",
    "\n",
    "Explanation of Findings\n",
    "\n",
    "\t•\tH3K27ac Mark: This histone modification is associated with active enhancers and promoters, which are key regulators of gene expression. The significant overlap suggests that Alzheimer’s-associated SNPs are enriched in regions where gene regulatory activity occurs.\n",
    "\t•\tDorsolateral Prefrontal Cortex: This brain region is critical for cognitive functions, such as decision-making and memory, both of which are impaired in Alzheimer’s disease. The enrichment of SNPs in this tissue’s regulatory regions aligns with our understanding of Alzheimer’s pathology.\n",
    "\t•\tImplications: The results indicate that these genetic variants likely influence the activity of nearby enhancers or promoters, thereby affecting the expression of genes associated with Alzheimer’s disease.\n",
    "\n",
    "\n",
    "Surprised by the Result?\n",
    "\n",
    "\t•\tNot Surprised: The result is consistent with the biological hypothesis that disease-associated SNPs are likely to influence gene regulatory mechanisms in tissues relevant to the disease. Previous studies have implicated dysregulated gene expression in Alzheimer’s, and histone modifications like H3K27ac provide a window into these changes.\n",
    "\t•\tWhy It’s Expected:\n",
    "\t1.\tAlzheimer’s is a neurodegenerative disease that involves complex regulatory networks.\n",
    "\t2.\tThe dorsolateral prefrontal cortex is a well-studied region in Alzheimer’s research.\n",
    "\t3.\tThe SNPs used in this analysis were pre-identified as associated with the disease, making it plausible they would fall within active regulatory regions.\n",
    "\n",
    "The findings underscore the importance of integrating genetic and epigenetic data to better understand the molecular underpinnings of Alzheimer’s disease. These results point toward potential regulatory elements that might mediate the effects of genetic variants, paving the way for functional studies and therapeutic targeting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENCODE: Finding Active regulatory regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You also know that H3K9me3 is a sign of *repressed* chromatin. Download and unzip the narrowPeak bed file for mouse H3K9me3 data (file **ENCFF234GVB**). Then, using the intersect command and -v flag, count the number of genes from MeAc_genes.bed that do **NOT** also have a H3K9me3 mark. MeAc_genes.bed was generated in the 2nd Encode Module and has been provided in this folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4.** (5 points) Write the bedtools command(s) to do this."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Step 1: Sort both BED files (if not already sorted)\n",
    "sort -k1,1 -k2,2n MeAc_genes.bed > MeAc_genes.sorted.bed\n",
    "sort -k1,1 -k2,2n ENCFF234GVB.bed > ENCFF234GVB.sorted.bed\n",
    "\n",
    "# Step 2: Find entries in MeAc_genes.bed that do NOT overlap with H3K9me3 marks\n",
    "bedtools intersect -v -a MeAc_genes.sorted.bed -b ENCFF234GVB.sorted.bed > MeAc_genes_no_H3K9me3.bed\n",
    "\n",
    "# Step 3: Count the number of genes that do NOT have H3K9me3 marks\n",
    "wc -l MeAc_genes_no_H3K9me3.bed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5.** (5 points) How many genes from MeAc_genes.bed do not have a H3K9me3 mark?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "69 genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6.** (5 points) Are you convinced that these genes are truly active genes in embroynic mouse liver? Do you think that there may be some genes in liver_genes.txt that are expressed that we missed? Why or why not? What complexities are we overlooking?\n",
    "\n",
    "*Hint: Think about issues such as where different marks should be located relative to the gene (from the Enhancer paper in the prelab), whether bedtool's window command was the ideal one to use, and cell type heterogeneity*."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "While the analysis identifies 69 genes from MeAc_genes.bed that do not overlap with H3K9me3 marks, this result alone is not sufficient to conclusively determine that these genes are truly active in embryonic mouse liver. There are several complexities and limitations to consider. First, the location of epigenetic marks relative to genes is critical. H3K9me3 is associated with repressed chromatin and is typically found in promoters of inactive genes. However, active gene regulation can occur at distal enhancers marked by modifications like H3K27ac or H3K4me1, which were not considered in this analysis. Furthermore, BEDTools only examines direct overlap and may miss regulatory elements located upstream or downstream of a gene. Enhancers, which often regulate genes from a distance, could have been overlooked. Second, cell-type and tissue heterogeneity pose challenges. The H3K9me3 dataset represents embryonic mouse liver, a tissue composed of multiple cell types with distinct gene expression profiles. Active genes in one cell type may be inactive in others, and signals averaged across heterogeneous cell types may dilute specific marks associated with certain cell populations. Third, the sensitivity of tools and analysis is a limitation. The analysis relied on direct overlap without extending genomic regions around genes. Using the bedtools window command with a larger window size could have captured more distant regulatory relationships. Moreover, other marks associated with active transcription, such as H3K4me3 at promoters or H3K27ac at enhancers, were not analyzed, leaving the determination of activity incomplete. Finally, functional validation and expression data are necessary for confirmation. The absence of H3K9me3 does not necessarily imply transcriptional activity, and RNA-seq or transcriptomic datasets from embryonic mouse liver would be needed to verify actual gene expression levels. Gene expression is influenced by multiple layers of regulation, including transcription factors, chromatin looping, and 3D genome organization, none of which were captured in this analysis. While the absence of H3K9me3 is a good indicator that these genes are not repressed, the limitations in the marks analyzed, the regulatory element placement, tissue heterogeneity, and the lack of direct expression validation suggest that some active genes may have been missed. Combining chromatin mark data with RNA-seq or ATAC-seq data and refining the analysis with larger windows or enhancer marks would provide a more comprehensive understanding of gene activity in embryonic mouse liver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Pipelines and Automation of analysis (Rscripts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In module 22, you created an Rscript that you can use for high-throughput analysis of some data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7.** (5 points) Provide a copy of the Rscript that you created in your `H03_Homework-III` directory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/opt/homebrew/lib/R/4.4/site-library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n",
      "── \u001b[1mAttaching core tidyverse packages\u001b[22m ──────────────────────── tidyverse 2.0.0 ──\n",
      "\u001b[32m✔\u001b[39m \u001b[34mdplyr    \u001b[39m 1.1.4     \u001b[32m✔\u001b[39m \u001b[34mreadr    \u001b[39m 2.1.5\n",
      "\u001b[32m✔\u001b[39m \u001b[34mforcats  \u001b[39m 1.0.0     \u001b[32m✔\u001b[39m \u001b[34mstringr  \u001b[39m 1.5.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2  \u001b[39m 3.5.1     \u001b[32m✔\u001b[39m \u001b[34mtibble   \u001b[39m 3.2.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mlubridate\u001b[39m 1.9.4     \u001b[32m✔\u001b[39m \u001b[34mtidyr    \u001b[39m 1.3.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mpurrr    \u001b[39m 1.0.2     \n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[36mℹ\u001b[39m Use the conflicted package (\u001b[3m\u001b[34m<http://conflicted.r-lib.org/>\u001b[39m\u001b[23m) to force all conflicts to become errors\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error: Please provide two input files: gene expression file and gene location file.\n",
     "output_type": "error",
     "traceback": [
      "Error: Please provide two input files: gene expression file and gene location file.\nTraceback:\n",
      "1. .handleSimpleError(function (cnd) \n . {\n .     watcher$capture_plot_and_output()\n .     cnd <- sanitize_call(cnd)\n .     watcher$push(cnd)\n .     switch(on_error, continue = invokeRestart(\"eval_continue\"), \n .         stop = invokeRestart(\"eval_stop\"), error = invokeRestart(\"eval_error\", \n .             cnd))\n . }, \"Please provide two input files: gene expression file and gene location file.\", \n .     base::quote(eval(expr, envir)))"
     ]
    }
   ],
   "source": [
    "### Gene Expression Standardization Pipeline\n",
    "### Author: Vidur Saigal\n",
    "### Created on: 2024-12-09\n",
    "### Description: This pipeline standardizes gene expression values by merging gene expression and \n",
    "### location datasets, calculating mean and standard deviation, and outputting the normalized results.\n",
    "\n",
    "## BLOCK ZERO\n",
    "## Load necessary libraries\n",
    "install.packages('tidyverse', repos='http://cran.us.r-project.org')\n",
    "library(tidyverse)\n",
    "\n",
    "## BLOCK 0.5\n",
    "## Obtain file paths for input files from the command line\n",
    "args <- commandArgs(trailingOnly = TRUE)\n",
    "if (length(args) != 2) {\n",
    "  stop(\"Please provide two input files: gene expression file and gene location file.\")\n",
    "}\n",
    "gene_expr_file <- args[1]  # First argument: Gene expression file\n",
    "gene_loc_file <- args[2]   # Second argument: Gene location file\n",
    "\n",
    "## BLOCK ONE\n",
    "## Read input files and merge them based on 'geneid', then reorganize columns\n",
    "GExpr <- read.table(file = gene_expr_file, sep = \",\", header = TRUE)\n",
    "Loc <- read.table(file = gene_loc_file, sep = \",\", header = TRUE)\n",
    "z <- left_join(GExpr, Loc, by = \"geneid\") %>%\n",
    "      relocate(chr, pos, .after = geneid)\n",
    "\n",
    "## BLOCK TWO\n",
    "## Calculate average and standard deviation for each gene across expression data\n",
    "x <- z %>%\n",
    "  rowwise(geneid) %>%\n",
    "  mutate(ave = mean(c_across(starts_with(\"GTEX\")), na.rm = TRUE)) %>%\n",
    "  mutate(sd = sd(c_across(starts_with(\"GTEX\")), na.rm = TRUE)) %>%\n",
    "  relocate(ave, sd, .after = pos)\n",
    "\n",
    "## BLOCK THREE\n",
    "## Standardize gene expression values for each gene\n",
    "for (i in seq_along(rownames(x))) {\n",
    "  for (j in 6:length(x[i, ])) {\n",
    "    this_ave <- x[i, ]$ave\n",
    "    this_sd <- x[i, ]$sd\n",
    "    x[i, j] <- (x[i, j] - this_ave) / this_sd\n",
    "  }\n",
    "}\n",
    "\n",
    "## BLOCK FOUR\n",
    "## Recalculate average and standard deviation for standardized values\n",
    "x <- x %>%\n",
    "  rowwise(geneid) %>%\n",
    "  mutate(ave_std = mean(c_across(starts_with(\"GTEX\")), na.rm = TRUE)) %>%\n",
    "  mutate(sd_std = sd(c_across(starts_with(\"GTEX\")), na.rm = TRUE)) %>%\n",
    "  relocate(ave_std, sd_std, .after = sd)\n",
    "\n",
    "## BLOCK FIVE\n",
    "## Write the output to a file with a unique name based on the input gene expression file\n",
    "outfile <- paste0(gene_expr_file, \".std\")\n",
    "write.table(\n",
    "  x,\n",
    "  file = outfile,\n",
    "  sep = \",\",\n",
    "  row.names = FALSE,\n",
    "  col.names = TRUE,\n",
    "  quote = FALSE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q8.** (5 points) Now, let's unlock the power of automation. We have provided you with 3 data sets (exp1, exp2, exp3):\n",
    "\n",
    "    /data\n",
    "    \n",
    "Using your script, analyze each of the 3 data sets provided and generate outputs!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "$ for prefix in exp1 exp2 exp3; do Rscript GExpr_std_pipe.R \"./data/GExp_snippet_${prefix}.csv\" \"./data/Loc_snippet_${prefix}.csv\"; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q9a** (3 points) In an R code block, read each of the 3 output files you created into R and print the contents to your notebook. \n",
    "\n",
    "Provide your code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Contents of file: ./data/GExp_snippet_exp1.csv.std \n",
      "     geneid chr      pos        ave        sd       ave_std sd_std   GTEX.A01\n",
      "1  ENSG0001  11  1023832  1.3581406 0.6740508 -1.221245e-16      1  0.5727588\n",
      "2  ENSG0002  17   199299  0.6587927 0.5591561 -1.554312e-16      1  0.4471766\n",
      "3  ENSG0003  22   111238 -1.1255273 2.3377276  0.000000e+00      1  1.3713467\n",
      "4  ENSG0004   1   178623 -1.3107034 0.7519454  3.330669e-17      1 -1.0207422\n",
      "5  ENSG0005   2  9919267 -1.1706817 0.7299675 -1.190020e-16      1 -0.2275287\n",
      "6  ENSG0006   3    17727  0.4803374 1.1899238  1.117162e-16      1  0.1247388\n",
      "7  ENSG0007   4   129378  0.1127173 1.8979994  1.110223e-17      1 -1.0528440\n",
      "8  ENSG0008   5  1929388  0.2793343 1.9080912  2.220446e-17      1  0.4922006\n",
      "9  ENSG0009   6   884843 -0.1478188 2.3057015 -8.326673e-17      1  0.1493075\n",
      "10 ENSG0010   7 27830940 -1.3712548 1.5034761 -9.645063e-17      1  2.1208943\n",
      "      GTEX.A02   GTEX.A03    GTEX.A04   GTEX.A05   GTEX.A06   GTEX.A07\n",
      "1  -0.54168425 -1.3459630  1.44778682  1.2853132 -1.0057066 -0.6266851\n",
      "2   0.02451184 -1.8481557  0.82249792 -0.7911435  0.9508667 -0.7451553\n",
      "3  -0.26501419 -0.1301137 -0.08741094  0.3276414 -1.2403284  0.5334478\n",
      "4  -0.06527904 -1.2512817  0.54581650 -1.1792261  1.0945849  0.6837389\n",
      "5  -0.50708644  0.5922505 -1.44316684  0.2246246  0.4698755  0.4271114\n",
      "6  -0.39020938  1.4292617  0.05741977 -0.3922045  2.9777529  0.2517706\n",
      "7   0.01691362  1.4762570  0.46020676 -1.9424537  0.7359685  0.7149618\n",
      "8   0.25925001 -1.4420933  0.73437934  0.1437426 -0.8243461 -0.5679477\n",
      "9  -0.26739661  0.1162106  0.11836087  1.2920085  0.7480639  1.0429705\n",
      "10  0.19358653 -1.3725299 -1.48374591  0.6391415 -0.3875657 -0.8435823\n",
      "      GTEX.A08   GTEX.A09   GTEX.A10   GTEX.A11  GTEX.A12   GTEX.A13\n",
      "1   0.01270767  0.4446941 -0.7114580 -0.8022134 0.3320743  2.3169123\n",
      "2  -1.66975701  0.1827512 -0.1665071  1.2009003 0.4288136 -0.5504417\n",
      "3   1.09274008  0.7831218 -0.8428543 -2.9076793 0.7753024  0.3629078\n",
      "4  -1.58821786 -0.1800539 -0.4962385 -0.2359048 0.6544668  1.1858526\n",
      "5   0.63278047  1.0412941 -2.2410227 -0.7079666 0.2775525 -0.1982894\n",
      "6  -0.87014898 -0.9269522 -1.1607234  0.1879987 0.2952001 -1.6756728\n",
      "7   0.46608842 -0.5646939  0.7097570 -1.4361666 0.4511284 -1.3194182\n",
      "8  -1.15403223  0.7578791 -0.5623205 -0.8385053 2.9807193  0.5052871\n",
      "9  -0.93412220 -1.4491590 -0.3848167 -0.1492829 1.7898928 -1.7274277\n",
      "10 -0.46755941 -0.6451921 -0.1099171  0.4832022 1.5345328  1.9652844\n",
      "      GTEX.A14     GTEX.A15   GTEX.A16   GTEX.A17      GTEX.A18      GTEX.A19\n",
      "1   0.83556973 -0.265382956 -1.1774154 -0.5488830  0.1099085095  0.8499867432\n",
      "2  -0.80731702  0.336560288  1.3250874 -1.4985401 -0.0009146909  0.7951334669\n",
      "3  -0.90070361  1.457824574 -0.1091780 -0.2258790  0.3222647194  0.1843699528\n",
      "4  -0.50756126  2.467557926 -0.4076524  0.7492892 -0.9486856878 -0.0993968062\n",
      "5   1.67814407 -1.971779122 -0.3991942  0.8216860  0.6052513911  0.8788486808\n",
      "6   0.03645188 -0.492940644  1.0854144 -0.3989581 -0.4274496532  0.1734641453\n",
      "7   1.39621348 -0.516181273  0.7229584 -0.9190514 -0.9045534170  0.5361666846\n",
      "8   0.11320208 -0.157703287  0.5786595  0.8385359 -0.6260027899  0.0002681798\n",
      "9   0.83752595 -0.091824616  0.7956349 -1.5835681  1.1168168324 -0.4582605143\n",
      "10 -0.32789007  0.002481662 -1.2295959  0.5119373 -0.2864533644 -0.1897100225\n",
      "      GTEX.A20\n",
      "1  -1.18232042\n",
      "2   1.56363279\n",
      "3  -0.50180598\n",
      "4   0.59893352\n",
      "5   0.04661492\n",
      "6   0.11578681\n",
      "7   0.96874253\n",
      "8  -1.23117267\n",
      "9  -0.96093404\n",
      "10 -0.10731889\n",
      "\n",
      "Contents of file: ./data/GExp_snippet_exp2.csv.std \n",
      "     geneid chr     pos        ave        sd       ave_std sd_std    GTEX.A01\n",
      "1  ENSG1001   1   10000 -1.9247600 1.2217909 -3.608225e-17      1 -0.68733454\n",
      "2  ENSG1002   1   12000 -1.2033356 0.8770956 -1.325329e-16      1  1.20481827\n",
      "3  ENSG1003   1   14000 -1.5868779 1.6423598 -1.526557e-17      1 -0.55187689\n",
      "4  ENSG1004   1   16000  2.0604484 1.5250447  5.551115e-17      1  0.80054232\n",
      "5  ENSG1005   1   20000  0.6091289 0.6207948  1.193490e-16      1 -0.51392351\n",
      "6  ENSG1006   1  100000  0.8417114 0.6346225  3.885781e-17      1  0.34728120\n",
      "7  ENSG1007   1  110000  2.5007082 2.9532352 -1.686151e-16      1 -0.73763078\n",
      "8  ENSG1008   1  120000  1.4461517 2.1804831  7.494005e-17      1 -0.08930535\n",
      "9  ENSG1009   1 1000000 -1.5893805 2.6941554 -1.110223e-17      1  0.39350701\n",
      "10 ENSG1010   1 1100000 -1.1420478 2.3828026 -8.604228e-17      1  1.04989765\n",
      "11 ENSG1011   1 1200000  0.9171783 0.6094182 -7.771561e-17      1  0.57762837\n",
      "      GTEX.A02   GTEX.A03   GTEX.A04   GTEX.A05   GTEX.A06   GTEX.A07\n",
      "1   0.63192779  0.6475317 -0.9177682 -0.3913525  1.1562375  0.3462377\n",
      "2   0.51852296  0.9132021 -0.8221633  0.1211301 -0.5725277 -0.6414254\n",
      "3  -0.35210703  0.5457702 -2.3570747  0.2087100 -0.4107231  0.5962420\n",
      "4  -2.24872413  0.7267644 -0.1217413  2.6340322  0.0375570 -1.6220228\n",
      "5  -1.18195344  0.9088816 -0.5570900 -1.5680900 -0.4980511  1.0329314\n",
      "6  -0.15085143  1.1532420  1.7285834 -1.4374208 -0.3102938  1.7566238\n",
      "7  -0.27833932  1.8422804 -2.1681104 -0.4574792 -0.8741727 -0.5081019\n",
      "8   0.16993989  0.2475909  0.6051624 -1.8224208  0.3930206 -1.8081789\n",
      "9   0.98104615 -0.3599669  0.1300759  0.8736451  1.5843779 -0.1737603\n",
      "10  0.09495686  0.3479883 -1.7636075  0.3573334 -0.6869393  1.2958168\n",
      "11  0.40094157  0.8961460  0.8976091  0.8373494 -1.5508206  0.3656862\n",
      "      GTEX.A08   GTEX.A09    GTEX.A10   GTEX.A11    GTEX.A12    GTEX.A13\n",
      "1   0.33012737  0.7969595 -0.56977187  2.2089627 -1.01769541 -0.46415102\n",
      "2   0.76616130 -0.8092452 -0.43981886  0.7930792  0.21226194 -0.65339706\n",
      "3  -0.36985137  0.1661053 -1.62709378  1.3777357  0.06783438 -0.22432510\n",
      "4   0.31927150  1.0800969 -0.03653014 -0.7481383  0.61951464  0.47671292\n",
      "5  -1.58348904  1.2189357  0.50248079 -0.8859772  1.65703082 -1.00745027\n",
      "6  -1.10192875 -0.7379962 -0.56966937 -1.6331426  0.50965284  0.40029335\n",
      "7  -0.09313184 -1.0248729  1.17810395 -0.2566841  1.49809706  0.02758543\n",
      "8   0.81224281  1.5994454  1.57221878 -1.0600412  0.40635566 -0.38854812\n",
      "9   0.80466298 -0.1689925 -1.07465445  0.2173986  0.55435837  0.36568792\n",
      "10  0.15573210 -0.1738925 -0.50995943  0.9336224 -0.29410277  0.37107197\n",
      "11 -0.98830626 -0.4249723 -0.62848029  1.2964033  1.30779982  1.81429980\n",
      "      GTEX.A14    GTEX.A15    GTEX.A16     GTEX.A17    GTEX.A18    GTEX.A19\n",
      "1   0.83910988  1.40426977 -1.62619012 -0.488763901 -1.46832129 -0.55917742\n",
      "2   0.21288376 -2.81063567  0.70257656  1.722285124 -0.94061752  0.42445739\n",
      "3   1.32651417  0.70050604  2.08723042 -0.687175261 -0.26811368 -0.43672016\n",
      "4  -0.05045294 -0.22417303 -0.29558484 -0.595375597 -0.05590734 -0.41258515\n",
      "5  -0.31655871  0.69288960  1.48050824  0.573007017  0.39572362 -0.57416918\n",
      "6  -0.43607830 -0.94776939  0.18846979 -0.002157534  0.32508959  1.57008776\n",
      "7   1.56080601 -0.05533049  0.95610953  0.106374306  0.16885301 -0.94715048\n",
      "8  -1.47330479 -0.69972241  0.02228216 -0.268771930  1.34935200  0.13424520\n",
      "9  -0.57716628 -3.05186304 -0.41074097 -0.928810716 -0.27743983 -0.04576327\n",
      "10 -1.18433065 -1.33179704 -0.08397085 -1.774746489  1.77001819  1.20543408\n",
      "11 -0.96140999 -0.15386153 -0.41161279  0.100243121 -1.49463832 -0.55708344\n",
      "      GTEX.A20\n",
      "1  -0.17083757\n",
      "2   0.09845188\n",
      "3   0.20841290\n",
      "4  -0.28325628\n",
      "5   0.22436376\n",
      "6  -0.65201564\n",
      "7   0.06279443\n",
      "8   0.29843775\n",
      "9   1.16439827\n",
      "10  0.22147485\n",
      "11 -1.32292123\n",
      "\n",
      "Contents of file: ./data/GExp_snippet_exp3.csv.std \n",
      "     geneid chr     pos         ave        sd       ave_std sd_std   GTEX.A01\n",
      "1  ENSG2001   2   10000  0.30589365 1.2617640 -6.661338e-17      1  0.3095768\n",
      "2  ENSG2002   2   12000 -0.32760643 2.9240340 -1.110223e-16      1  1.2645516\n",
      "3  ENSG2003   2   14000  1.16168510 0.8319616 -2.775558e-17      1  0.8518956\n",
      "4  ENSG2004   2   16000 -1.94018212 0.6543013  2.220446e-17      1 -1.4857129\n",
      "5  ENSG2005   2   20000  1.40311747 0.5776564  9.159340e-17      1 -0.7883748\n",
      "6  ENSG2006   2  100000 -1.53121320 1.7378136  8.881784e-17      1 -0.6653853\n",
      "7  ENSG2007   2  110000 -0.34913339 1.4094469  1.110223e-17      1 -0.3394840\n",
      "8  ENSG2008   2  120000 -1.78143289 2.1481143  6.661338e-17      1  0.9739800\n",
      "9  ENSG2009   2 1000000 -0.05664462 2.7274542  1.110223e-17      1  1.0053407\n",
      "10 ENSG2010   2 1100000  0.43181509 1.7582304 -4.440892e-17      1  0.2396912\n",
      "11 ENSG2011   2 1200000 -0.95437306 0.4834587 -2.220446e-17      1  0.3785290\n",
      "     GTEX.A02   GTEX.A03    GTEX.A04   GTEX.A05    GTEX.A06    GTEX.A07\n",
      "1   1.0923112 -0.4170197 -0.19503130 -0.3807651 -0.95313971 -0.49649432\n",
      "2   1.7740880 -0.9026710 -1.09547454  0.3627192 -0.57506564 -0.35221768\n",
      "3  -1.0913580  0.5227025  1.65123956 -0.8429199  0.97161446  0.86111181\n",
      "4  -0.4591129  0.9038748 -0.62135074 -0.5826226  0.27857491 -0.22257037\n",
      "5   0.5938148 -0.6862165 -0.41278303 -0.6313349 -0.35441529 -0.92769013\n",
      "6  -1.0654910 -1.2113539  1.09606461 -0.6497642 -0.05620027  1.19081039\n",
      "7  -0.2321926  0.1001466 -0.66029788  0.3831034  0.83920517  0.62829059\n",
      "8   0.8062174 -1.0289519  1.01249346  0.5958395 -0.06485530  1.78037082\n",
      "9  -0.4626810  0.5034134  1.73592417  0.5077320  0.32441546 -0.67058327\n",
      "10 -0.1881799  1.7029233 -0.46591220 -0.3938914 -0.60826675 -0.03089999\n",
      "11 -0.5582058 -0.4681547  0.01422822  0.3007619  0.88238055  0.18048916\n",
      "      GTEX.A08    GTEX.A09    GTEX.A10    GTEX.A11    GTEX.A12   GTEX.A13\n",
      "1   0.99890192 -1.74197991 -0.95204834 -1.13441248  1.96208702 -0.2857105\n",
      "2  -0.01475201 -0.84558760 -0.14753767  1.03019085  0.66087534 -0.9649054\n",
      "3  -0.31729822  0.60873987 -0.50904137  1.14357416  1.12510227  0.5757480\n",
      "4   0.93043165  0.92325713 -0.92489790  2.06436494 -1.83271686  0.4075007\n",
      "5   2.06864626 -1.67623818 -0.08942266  0.85518345 -0.04318306 -0.6897535\n",
      "6  -0.75214977  1.03371575  0.05070325 -0.06582444 -1.02973932  1.5125695\n",
      "7  -0.23856033  2.10649829 -1.01643530  0.97867979 -0.01705638 -2.6207825\n",
      "8   0.57503195  1.14978384 -0.91259942  0.76328865 -0.67816768  0.6754911\n",
      "9  -1.03537832 -0.24496550 -0.22714496 -1.69262389  1.46958915  0.5510300\n",
      "10 -0.01180505 -0.08941791 -1.26126548 -0.43451387  0.73788214 -0.3030264\n",
      "11  1.31976247  0.08904350 -0.19517126 -0.91964245  0.78040327 -0.8934553\n",
      "       GTEX.A14   GTEX.A15    GTEX.A16    GTEX.A17   GTEX.A18    GTEX.A19\n",
      "1  -0.143205215  0.6776563  0.81716027 -0.02495857 -0.9401828 -0.18655202\n",
      "2  -0.006320366 -0.5702648 -0.75602086 -1.00522535 -1.1125058  1.48647105\n",
      "3   0.256652999 -2.0911542 -0.58657646 -1.01484131 -1.3475732 -0.13030674\n",
      "4   0.649908436  0.4058735  0.02693258 -1.33979607 -0.1577756 -0.37871282\n",
      "5  -0.573916526 -0.9297355  0.92074890  1.57107957  1.7835060 -0.03322853\n",
      "6  -1.216413597  0.5693857  1.28193909  1.34370573 -1.0323204  0.71211250\n",
      "7   0.201492942 -1.2098630  0.60530781 -0.21011928  0.9301683  0.58555462\n",
      "8  -0.083355465  0.2328568 -1.31492278 -1.77799108 -1.1689464 -0.37575447\n",
      "9  -1.293063525  0.4614882 -1.19166949 -1.03424133 -0.6810609  1.43214547\n",
      "10 -0.329479286  1.0274366 -0.83691603 -1.63065615  2.3184012 -0.90125094\n",
      "11  0.777959632  1.4255570  1.42961446 -2.63954591 -0.2202847 -1.20816264\n",
      "      GTEX.A20\n",
      "1   1.99380648\n",
      "2   1.76965262\n",
      "3  -0.63731177\n",
      "4   1.41455023\n",
      "5   0.04331368\n",
      "6  -1.04636435\n",
      "7  -0.81365617\n",
      "8  -1.15980910\n",
      "9   0.54233351\n",
      "10  1.45914700\n",
      "11 -0.47610653\n"
     ]
    }
   ],
   "source": [
    "# Define the prefixes for the three datasets\n",
    "prefixes <- c(\"exp1\", \"exp2\", \"exp3\")\n",
    "\n",
    "# Loop through each prefix, read the corresponding output file, and print its contents\n",
    "for (prefix in prefixes) {\n",
    "  # Construct the file path for the output file\n",
    "  file_path <- paste0(\"./data/GExp_snippet_\", prefix, \".csv.std\")\n",
    "  \n",
    "  # Read the output file into R\n",
    "  data <- read.csv(file_path, header = TRUE)\n",
    "  \n",
    "  # Print a message indicating which file is being printed\n",
    "  cat(\"\\nContents of file:\", file_path, \"\\n\")\n",
    "  \n",
    "  # Print the contents of the file\n",
    "  print(data)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "**Q9b** (2 points) Using a **SINGLE** UNIX command, view the contents of all three output files. HINT: the commands `head` and `cat` can display multiple files with only one command - you might need to look up how to do this.\n",
    "\n",
    "Provide your code below:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "$ cat ./data/GExp_snippet_exp1.csv.std ./data/GExp_snippet_exp2.csv.std ./data/GExp_snippet_exp3.csv.std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q10.** (5 points) You'll note that if you had 1000s of experiments to analyze, it would be a real pain to write out the command line for each one -- you have better things to do than that!\n",
    "\n",
    "What could you do to save yourself from needing to do that? How would you modify the code to achieve that? (Provide a general description, but no need to write specific code)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "1. Use File Discovery\n",
    "\t•\tInstead of specifying files manually, use a function to scan a directory (e.g., the /data folder) for all input files matching a specific pattern (e.g., GExp_snippet_*.csv for gene expression files and Loc_snippet_*.csv for location files).\n",
    "\t•\tExample: Use a file discovery method (list.files() in R or ls in UNIX) to identify all relevant files.\n",
    "\n",
    "2. Pair Files Dynamically\n",
    "\t•\tIdentify and pair matching gene expression and location files based on naming conventions. For example:\n",
    "\t•\tIf you find GExp_snippet_exp1.csv, pair it with Loc_snippet_exp1.csv.\n",
    "\n",
    "3. Automate Batch Processing\n",
    "\t•\tOnce the files are paired, iterate over them using a loop in your script. This avoids manually specifying file names in the command line.\n",
    "\t•\tProcess each pair in sequence and generate corresponding output files.\n",
    "\n",
    "4. Output Naming\n",
    "\t•\tDynamically name the output files based on the input file names (e.g., append .std to the gene expression file name).\n",
    "\n",
    "5. Optional Parallelization\n",
    "\t•\tFor large-scale datasets, consider using parallel processing to handle multiple file pairs concurrently, reducing processing time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automation / re-analysis Using Jupyter Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Module 23 (Pharmcology), you will have probably noted that you could have tabulated virtually all of the above in excel. \n",
    "\n",
    "However, in a true high-throughput screening assay, you will have **hundreds** of plates to process. That's too much for even one human to do in excel, perfectly! \n",
    "\n",
    "You may also have noticed that through doing this assignment, you have written a 'generic' pipeline to process a single plate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q11.** (5 points) Return to the in-class module. In order to process a different plate, called `plate2`, what would you change in the pipeline you created?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "To process a different plate, such as plate2, using the pipeline you created, you would only need to make a few small changes:\n",
    "\n",
    "\t1.\tChange the Input File Name:\n",
    "Update the variable that contains the plate file name (myplatefile) to point to plate2.csv.\n",
    "\n",
    "\t2.\tUpdate the Plate Name Variable:\n",
    "Update the myplatename variable to reflect the new plate name (plate2).\n",
    "\n",
    "\t3.\tReload the Data:\n",
    "Ensure that the new data is loaded into myplate from the updated file.\n",
    "\n",
    "\t4.\tThe Rest of the Pipeline:\n",
    "Once myplatefile and myplatename are updated, the rest of the pipeline will process the new plate without any further changes because it was written generically. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q12.** (5 points) In your module 23 directory, we included data from 6 additional plates. \n",
    "\n",
    "Process each and report here (excluding controls):\n",
    "- the Z prime factor for each plate  \n",
    "- the number of cells that gave lower than a **-4** normalized score, excluding controls, per plate. Note that rather than counting the results on the heatmap, you could `sum()` within the appropriate part of the heatmap table (excluding the controls, of course)\n",
    "\n",
    "To do this, you could change the plate and re-run the markdown, and record the results in the cells below."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Z-factor for plate 2 is: 0.6042501\n",
    "Z-factor for plate 3 is: 0.4285661\n",
    "Z-factor for plate 4 is: 0.4298547\n",
    "Z-factor for plate 5 is: 0.6598047\n",
    "Z-factor for plate 6 is: 0.5519932\n",
    "Z-factor for plate 7 is: 0.5360766"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Number of cells less than -4 for plate 2 is: 48\n",
    "Number of cells less than -4 for plate 3 is: 7\n",
    "Number of cells less than -4 for plate 4 is: 11\n",
    "Number of cells less than -4 for plate 5 is: 1\n",
    "Number of cells less than -4 for plate 6 is: 3\n",
    "Number of cells less than -4 for plate 7 is: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that in these data, you do not actually have any sample names attached to your data, e.g. what genes you actually screened.\n",
    "\n",
    "Imagine that you were provided a file that looked like the following:\n",
    "\n",
    "    sampleid,row,col,plate\n",
    "    87234,C,3,1\n",
    "    7134,C,4,1\n",
    "    ...\n",
    "    81672,P,22,7\n",
    "\n",
    "i.e. a file with 2240 rows (+1 header) where each sampleids was mapped to a corresponding row and column. Note that positive and negative control columns are excluded.\n",
    "\n",
    "**Q13.** (5 points) Imagine that you now wanted to obtain the sampleids (i.e., the gene code id!) from the a set of cells that were of interest, the 'hits' from the screen. \n",
    "\n",
    "For that, imagine that you had a second file which collated all of the cells across all plates which had a normalized Z-score less than -5. e.g., it looked like this:\n",
    "\n",
    "    row,col,plate\n",
    "    C,3,1\n",
    "    D,5,2\n",
    "    P,6,7\n",
    "\n",
    "Describe in words the steps that would allow a computer to print out the sampleids ONLY for the entries listed in this new file. To help you, we have provided the first two steps in the process. You complete the rest!\n",
    "   * Be specific in the details of what you would check for during your look-up.\n",
    "   * Hint: Pretend of you had two sheets of paper, each with your lists, and you had to do this 'by hand'. What would you do, step-by-step?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Step 1: Tell the computer to load the sampleid file into memory in R\n",
    "Step 2: Tell the computer to load the 'hit' file into memory in R\n",
    "Step 3: For each row in the hits_df (representing a hit), find the corresponding row in sampleid_df.\n",
    "\t•\tMatch on row, col, and plate. Specifically:\n",
    "\t•\tCheck if the row in hits_df matches the row in sampleid_df.\n",
    "\t•\tCheck if the col in hits_df matches the col in sampleid_df.\n",
    "\t•\tCheck if the plate in hits_df matches the plate in sampleid_df.\n",
    "Step 4: Extract the sampleid from sampleid_df for each matching hit.\n",
    "\t•\tOnce a match is found, retrieve the sampleid from the corresponding row in sampleid_df.\n",
    "Step 5: Store the extracted sampleids in a new list or data frame.\n",
    "\t•\tUse a loop or vectorized approach to iterate through hits_df, appending the matched sampleid to a new list.\n",
    "Step 6: Print the sampleids for all matched entries.\n",
    "\t•\tOutput the collected sampleids using print(), write to a file using write.csv(), or otherwise format them as required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q13 BONUS** (0 points) The following problem is optional, and will not affect your score on this homework in any way. However, if you provide a correct solution, you will get a \"first Dibs\" certificate for an event on the last day of class. *This will have nothing to do with your grade*.\n",
    "\n",
    "Write code in R that implements your solution to Q13. You may use tidyverse. We have provided both files described in the question in the `q13_bonus` directory. Note that this data was randomly generated, and does not match up with data from the Pharmacology module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction measurements and Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q14.** (6 points) In the context of machine learning problems, describe what is meant by the following terms:\n",
    "\n",
    "- Features\n",
    "- Examples\n",
    "- Labels\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Feature: Features are the individual measurable properties or characteristics of the data that are used by a machine learning model to make predictions or classifications. They represent the input variables.\n",
    "\n",
    "Example: Examples are individual data points or instances in the dataset. Each example consists of one or more features and, in supervised learning, may also include a label.\n",
    "\n",
    "Label: Labels are the target or output values that the machine learning model aims to predict. They are known outcomes provided during supervised learning for training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q15.** Imagine data from two trained models applied to a test set:\n",
    "\n",
    "Model 1:\n",
    "- Correctly labelled true positives examples: 601\n",
    "- Correctly laballed true negatives examples: 999\n",
    "- Actually negative examples labelled as positive: 371\n",
    "- Actually positive examples labelled as negative: 29\n",
    "\n",
    "Model 2:\n",
    "- Correctly labelled true positives examples: 255\n",
    "- Correctly laballed true negatives examples: 1345\n",
    "- Actually negative examples labelled as positive: 25\n",
    "- Actually positive examples labelled as negative: 375\n",
    "\n",
    "For calculations, we've inputted these numbers in R for you per the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "m1_tp = 601\n",
    "m1_tn = 999\n",
    "m1_fp = 371\n",
    "m1_fn = 29\n",
    "\n",
    "m2_tp = 255\n",
    "m2_tn = 1345\n",
    "m2_fp = 25\n",
    "m2_fn = 375"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q15a.** (6 points) What is the accuracy of Model 1 and Model 2, respectively?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model 1: 0.8 \n",
      "Accuracy of Model 2: 0.8 \n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy for Model 1\n",
    "m1_accuracy <- (m1_tp + m1_tn) / (m1_tp + m1_tn + m1_fp + m1_fn)\n",
    "\n",
    "# Calculate accuracy for Model 2\n",
    "m2_accuracy <- (m2_tp + m2_tn) / (m2_tp + m2_tn + m2_fp + m2_fn)\n",
    "\n",
    "# Print the results\n",
    "cat(\"Accuracy of Model 1:\", m1_accuracy, \"\\n\")\n",
    "cat(\"Accuracy of Model 2:\", m2_accuracy, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q15b.** (6 points) Of the examples that were *lablled* positive, what proportion are correctly predicted in Model 1? Model 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of Model 1: 0.6183128 \n",
      "Precision of Model 2: 0.9107143 \n"
     ]
    }
   ],
   "source": [
    "# Calculate precision for Model 1\n",
    "m1_precision <- m1_tp / (m1_tp + m1_fp)\n",
    "\n",
    "# Calculate precision for Model 2\n",
    "m2_precision <- m2_tp / (m2_tp + m2_fp)\n",
    "\n",
    "# Print the results\n",
    "cat(\"Precision of Model 1:\", m1_precision, \"\\n\")\n",
    "cat(\"Precision of Model 2:\", m2_precision, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q15c.** (6 points) Of the examples that are *actually* negative, what proportion are correctly predicted in Model 1? Model 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity of Model 1: 0.7291971 \n",
      "Specificity of Model 2: 0.9817518 \n"
     ]
    }
   ],
   "source": [
    "# Calculate specificity for Model 1\n",
    "m1_specificity <- m1_tn / (m1_tn + m1_fp)\n",
    "\n",
    "# Calculate specificity for Model 2\n",
    "m2_specificity <- m2_tn / (m2_tn + m2_fp)\n",
    "\n",
    "# Print the results\n",
    "cat(\"Specificity of Model 1:\", m1_specificity, \"\\n\")\n",
    "cat(\"Specificity of Model 2:\", m2_specificity, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q15d.** (6 points) Of the examples that are *actually* positive, what proportion are correctly predicted in Model 1? Model 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall of Model 1: 0.9539683 \n",
      "Recall of Model 2: 0.4047619 \n"
     ]
    }
   ],
   "source": [
    "# Calculate recall for Model 1\n",
    "m1_recall <- m1_tp / (m1_tp + m1_fn)\n",
    "\n",
    "# Calculate recall for Model 2\n",
    "m2_recall <- m2_tp / (m2_tp + m2_fn)\n",
    "\n",
    "# Print the results\n",
    "cat(\"Recall of Model 1:\", m1_recall, \"\\n\")\n",
    "cat(\"Recall of Model 2:\", m2_recall, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q15e.** (8 points) Based on the above, are these two models producing equivalent performance? Why or why not? Describe a situation where application of Model 1 would be preferrable to Model 2; and conversely, a situation where application of Model 2 might be preferrable to Model 1. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "No, these two models are not producing equivalent performance, even though their accuracy is the same (0.8 or 80%). The differences in precision, specificity, and recall reveal that the models behave differently depending on the positive or negative classification scenarios.\n",
    "\n",
    "Key Observations from the Metrics:\n",
    "\t1.\tModel 1:\n",
    "\t•\tHigh Recall (0.9538): It identifies a very high proportion of actual positive examples correctly.\n",
    "\t•\tModerate Precision (0.6183): A significant portion of the predicted positives are false positives.\n",
    "\t•\tModerate Specificity (0.7292): It struggles more with correctly identifying actual negatives compared to Model 2.\n",
    "\t2.\tModel 2:\n",
    "\t•\tHigh Specificity (0.9818): It identifies actual negatives very accurately.\n",
    "\t•\tHigh Precision (0.9107): Most of its positive predictions are correct.\n",
    "\t•\tLow Recall (0.4048): It misses a large proportion of actual positives, as indicated by a high false negative rate.\n",
    "\n",
    "When to Prefer Each Model:\n",
    "\t1.\tWhen to Use Model 1:\n",
    "\t•\tSituation: When it is critical to identify as many positives as possible (high recall is prioritized), even if it means tolerating more false positives.\n",
    "\t•\tExample Application:\n",
    "\t•\tDisease Screening: In medical diagnostics, it’s better to catch all potential positive cases (e.g., detecting a disease) even if some false positives occur, as they can be followed up with more specific tests.\n",
    "\t2.\tWhen to Use Model 2:\n",
    "\t•\tSituation: When it is critical to minimize false positives and prioritize precision and specificity, even if some positives are missed (lower recall).\n",
    "\t•\tExample Application:\n",
    "\t•\tFraud Detection: In financial systems, false positives (flagging legitimate transactions as fraudulent) can disrupt user experience. It is better to have fewer false alarms while still identifying fraudulent transactions accurately.\n",
    "\n",
    "\tModel 1 prioritizes recall, making it suitable for scenarios where missing positives has severe consequences.\n",
    "\tModel 2 prioritizes precision and specificity, making it suitable for scenarios where minimizing false positives is essential.\n",
    "\n",
    "Neither model is universally better; the choice depends on the specific goals and trade-offs of the application."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.2"
  },
  "name": "Online_database_in_class.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
