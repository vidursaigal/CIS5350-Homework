{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Set - III"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each Question/subquestion is worth **5 points**, unless indicated otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENCODE: Testing for Enrichment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to learn about possible genetic mechanisms of Alzheimer's using ENCODE data.\n",
    "\n",
    "SNPs associated with this disease can be found in `ALZ_SNPs_hg38.bed`.\n",
    "\n",
    "Choose an ENCODE data set from the ENCODE website that you think may be relevant to the disease (note: feel free to choose a tissue other than brain...there could be other tissues linked to the disease as well). Think both about tissue-type and ENCODE mark. Please do not use DNAse hypersensitivity or RNA-seq datasets. \n",
    "\n",
    "**Hint: it will be easiest if you find a data set with data in the bed file format.**\n",
    "\n",
    "**Note: Make sure the coordinates of the file you pick also use the hg38 reference genome**\n",
    "\n",
    "**Note: PLEASE try to pick a file size that is Less than 1 Gb -- this will make it run faster/Feasibly on CoCalc!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.** (2 points) What dataset did you choose and why? Include the tissue, epigenetic mark tested, and any identifying information, such as the name of the sample."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Dataset Chosen: Experiment summary for ENCSR872YGQ\n",
    "\t•\tAssay Type: Histone ChIP-seq\n",
    "\t•\tEpigenetic Mark: H3K27ac (associated with active enhancers and promoters)\n",
    "\t•\tTissue: Dorsolateral prefrontal cortex (Middle frontal area 46) from a female adult (89 years old) with Alzheimer’s disease\n",
    "\t•\tPlatform: Illumina NextSeq 500\n",
    "\t•\tProject: ENCODE4 (Bradley Bernstein Lab, Broad Institute)\n",
    "\n",
    "Why This Dataset?\n",
    "\t1.\tRelevance to Disease: The dorsolateral prefrontal cortex is a critical brain region for cognitive functions, heavily affected in Alzheimer’s disease. Examining histone modifications in this area can reveal transcriptional activity linked to disease pathology.\n",
    "\t2.\tEpigenetic Insight: The H3K27ac mark is essential for identifying active regulatory elements, such as enhancers and promoters, which may contribute to altered gene expression in Alzheimer’s disease.\n",
    "\t3.\tSpecificity and Quality: The dataset is highly specific to Alzheimer’s disease, and the ENCODE project ensures high-quality, standardized data. This experiment is unreplicated but uses rigorous ENCODE methodologies, enhancing confidence in the findings.\n",
    "\t4.\tData Compatibility: The dataset provides a BED narrowPeak file (hg38), which is compatible with the SNP analysis for Alzheimer’s disease (also in hg38 format).\n",
    "\n",
    "This dataset is ideal for identifying active genomic regions potentially linked to Alzheimer’s disease mechanisms, helping to pinpoint regulatory elements influenced by genetic variants associated with the condition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2:** (5 points) Now, test for significant overlap bewtween the Alzheimer's SNPs and your ENCODE mark. This time, instead of generating fake SNP sets, use the fisher exact test implemented in bedtools (http://bedtools.readthedocs.org/en/latest/content/tools/fisher.html). \n",
    "\n",
    "**NOTE: The fisher tool requires that your data is pre-sorted by chromosome and then by start position. e.g.**\n",
    "\n",
    "```bash\n",
    "$ sort -k1,1 -k2,2n in.bed > in.sorted.bed \n",
    "```\n",
    "    \n",
    "**for BED files, where `in.bed` is your input bed file and `in.sorted.bed` is the name that you want for the sorted output.**\n",
    "\n",
    "This test looks for an association between two classifications. In our case, we are looking for an association between being a SNP in ALZ_SNPs_hg38.bed and being in an interval from your ENCODE data set. Run this test on your datasets. \n",
    "\n",
    "**NOTE: We have provided you a pre-sorted genome file in this directory that you can use for this analysis (human.hg38.genome).**\n",
    "\n",
    "What is the two-tailed p-value? This is the p-value that under the null hypothesis (random chance), the given parameter (probability of overlap) is more extreme than what we observe in our data. Please include your unix commands in the top box and your answer in the bottom box."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "sort -k1,1 -k2,2n ENCFF983DQA.bed > ENCFF983DQA.sorted.bed\n",
    "sort -k1,1 -k2,2n AD_SNPs_hg38.bed > ALZ_SNPs_hg38.sorted.bed\n",
    "bedtools fisher -a ALZ_SNPs_hg38.sorted.bed -b ENCFF983DQA.sorted.bed -g human.hg38.genome"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "The two-tailed p-value is 2.874e-163.\n",
    "\n",
    "This extremely small value indicates that the observed overlap between Alzheimer’s-associated SNPs and H3K27ac-marked regions in the dorsolateral prefrontal cortex is highly statistically significant and is not due to random chance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3.** (5 points)  Was there a significant association between the disease-associated genetic variants and the ENCODE mark? Explain your findings to the best of your abilities. Are you suprised by the result? If so, why? If not, why not?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Yes, there was a significant association between the disease-associated genetic variants (SNPs from Alzheimer’s-associated regions) and the ENCODE mark (H3K27ac in the dorsolateral prefrontal cortex). The results from the Fisher’s exact test indicate an extremely small two-tailed p-value of 2.874e-163, and the enrichment ratio of 3.875 shows that the SNPs are almost 4 times more likely to fall within H3K27ac-marked regions than expected by random chance.\n",
    "\n",
    "Explanation of Findings\n",
    "\n",
    "\t•\tH3K27ac Mark: This histone modification is associated with active enhancers and promoters, which are key regulators of gene expression. The significant overlap suggests that Alzheimer’s-associated SNPs are enriched in regions where gene regulatory activity occurs.\n",
    "\t•\tDorsolateral Prefrontal Cortex: This brain region is critical for cognitive functions, such as decision-making and memory, both of which are impaired in Alzheimer’s disease. The enrichment of SNPs in this tissue’s regulatory regions aligns with our understanding of Alzheimer’s pathology.\n",
    "\t•\tImplications: The results indicate that these genetic variants likely influence the activity of nearby enhancers or promoters, thereby affecting the expression of genes associated with Alzheimer’s disease.\n",
    "\n",
    "\n",
    "Surprised by the Result?\n",
    "\n",
    "\t•\tNot Surprised: The result is consistent with the biological hypothesis that disease-associated SNPs are likely to influence gene regulatory mechanisms in tissues relevant to the disease. Previous studies have implicated dysregulated gene expression in Alzheimer’s, and histone modifications like H3K27ac provide a window into these changes.\n",
    "\t•\tWhy It’s Expected:\n",
    "\t1.\tAlzheimer’s is a neurodegenerative disease that involves complex regulatory networks.\n",
    "\t2.\tThe dorsolateral prefrontal cortex is a well-studied region in Alzheimer’s research.\n",
    "\t3.\tThe SNPs used in this analysis were pre-identified as associated with the disease, making it plausible they would fall within active regulatory regions.\n",
    "\n",
    "The findings underscore the importance of integrating genetic and epigenetic data to better understand the molecular underpinnings of Alzheimer’s disease. These results point toward potential regulatory elements that might mediate the effects of genetic variants, paving the way for functional studies and therapeutic targeting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENCODE: Finding Active regulatory regions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You also know that H3K9me3 is a sign of *repressed* chromatin. Download and unzip the narrowPeak bed file for mouse H3K9me3 data (file **ENCFF234GVB**). Then, using the intersect command and -v flag, count the number of genes from MeAc_genes.bed that do **NOT** also have a H3K9me3 mark. MeAc_genes.bed was generated in the 2nd Encode Module and has been provided in this folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4.** (5 points) Write the bedtools command(s) to do this."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5.** (5 points) How many genes from MeAc_genes.bed do not have a H3K9me3 mark?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "____ genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6.** (5 points) Are you convinced that these genes are truly active genes in embroynic mouse liver? Do you think that there may be some genes in liver_genes.txt that are expressed that we missed? Why or why not? What complexities are we overlooking?\n",
    "\n",
    "*Hint: Think about issues such as where different marks should be located relative to the gene (from the Enhancer paper in the prelab), whether bedtool's window command was the ideal one to use, and cell type heterogeneity*."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Pipelines and Automation of analysis (Rscripts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In module 22, you created an Rscript that you can use for high-throughput analysis of some data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7.** (5 points) Provide a copy of the Rscript that you created in your `H03_Homework-III` directory!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q8.** (5 points) Now, let's unlock the power of automation. We have provided you with 3 data sets (exp1, exp2, exp3):\n",
    "\n",
    "    /data\n",
    "    \n",
    "Using your script, analyze each of the 3 data sets provided and generate outputs!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q9a** (3 points) In an R code block, read each of the 3 output files you created into R and print the contents to your notebook. \n",
    "\n",
    "Provide your code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "**Q9b** (2 points) Using a **SINGLE** UNIX command, view the contents of all three output files. HINT: the commands `head` and `cat` can display multiple files with only one command - you might need to look up how to do this.\n",
    "\n",
    "Provide your code below:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q10.** (5 points) You'll note that if you had 1000s of experiments to analyze, it would be a real pain to write out the command line for each one -- you have better things to do than that!\n",
    "\n",
    "What could you do to save yourself from needing to do that? How would you modify the code to achieve that? (Provide a general description, but no need to write specific code)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automation / re-analysis Using Jupyter Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Module 23 (Pharmcology), you will have probably noted that you could have tabulated virtually all of the above in excel. \n",
    "\n",
    "However, in a true high-throughput screening assay, you will have **hundreds** of plates to process. That's too much for even one human to do in excel, perfectly! \n",
    "\n",
    "You may also have noticed that through doing this assignment, you have written a 'generic' pipeline to process a single plate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q11.** (5 points) Return to the in-class module. In order to process a different plate, called `plate2`, what would you change in the pipeline you created?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q12.** (5 points) In your module 23 directory, we included data from 6 additional plates. \n",
    "\n",
    "Process each and report here (excluding controls):\n",
    "- the Z prime factor for each plate  \n",
    "- the number of cells that gave lower than a **-4** normalized score, excluding controls, per plate. Note that rather than counting the results on the heatmap, you could `sum()` within the appropriate part of the heatmap table (excluding the controls, of course)\n",
    "\n",
    "To do this, you could change the plate and re-run the markdown, and record the results in the cells below."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Z-factor for plate 2 is: \n",
    "Z-factor for plate 3 is: \n",
    "Z-factor for plate 4 is: \n",
    "Z-factor for plate 5 is: \n",
    "Z-factor for plate 6 is: \n",
    "Z-factor for plate 7 is: "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Number of cells less than -4 for plate 2 is: \n",
    "Number of cells less than -4 for plate 3 is: \n",
    "Number of cells less than -4 for plate 4 is: \n",
    "Number of cells less than -4 for plate 5 is: \n",
    "Number of cells less than -4 for plate 6 is: \n",
    "Number of cells less than -4 for plate 7 is: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that in these data, you do not actually have any sample names attached to your data, e.g. what genes you actually screened.\n",
    "\n",
    "Imagine that you were provided a file that looked like the following:\n",
    "\n",
    "    sampleid,row,col,plate\n",
    "    87234,C,3,1\n",
    "    7134,C,4,1\n",
    "    ...\n",
    "    81672,P,22,7\n",
    "\n",
    "i.e. a file with 2240 rows (+1 header) where each sampleids was mapped to a corresponding row and column. Note that positive and negative control columns are excluded.\n",
    "\n",
    "**Q13.** (5 points) Imagine that you now wanted to obtain the sampleids (i.e., the gene code id!) from the a set of cells that were of interest, the 'hits' from the screen. \n",
    "\n",
    "For that, imagine that you had a second file which collated all of the cells across all plates which had a normalized Z-score less than -5. e.g., it looked like this:\n",
    "\n",
    "    row,col,plate\n",
    "    C,3,1\n",
    "    D,5,2\n",
    "    P,6,7\n",
    "\n",
    "Describe in words the steps that would allow a computer to print out the sampleids ONLY for the entries listed in this new file. To help you, we have provided the first two steps in the process. You complete the rest!\n",
    "   * Be specific in the details of what you would check for during your look-up.\n",
    "   * Hint: Pretend of you had two sheets of paper, each with your lists, and you had to do this 'by hand'. What would you do, step-by-step?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Step one: Tell the computer to load the sampleid file into memory in R\n",
    "Step two: Tell the computer to load the 'hit' file into memory in R\n",
    "Step three:\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q13 BONUS** (0 points) The following problem is optional, and will not affect your score on this homework in any way. However, if you provide a correct solution, you will get a \"first Dibs\" certificate for an event on the last day of class. *This will have nothing to do with your grade*.\n",
    "\n",
    "Write code in R that implements your solution to Q13. You may use tidyverse. We have provided both files described in the question in the `q13_bonus` directory. Note that this data was randomly generated, and does not match up with data from the Pharmacology module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction measurements and Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q14.** (6 points) In the context of machine learning problems, describe what is meant by the following terms:\n",
    "\n",
    "- Features\n",
    "- Examples\n",
    "- Labels\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Feature: \n",
    "\n",
    "Example:\n",
    "\n",
    "Label: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q15.** Imagine data from two trained models applied to a test set:\n",
    "\n",
    "Model 1:\n",
    "- Correctly labelled true positives examples: 601\n",
    "- Correctly laballed true negatives examples: 999\n",
    "- Actually negative examples labelled as positive: 371\n",
    "- Actually positive examples labelled as negative: 29\n",
    "\n",
    "Model 2:\n",
    "- Correctly labelled true positives examples: 255\n",
    "- Correctly laballed true negatives examples: 1345\n",
    "- Actually negative examples labelled as positive: 25\n",
    "- Actually positive examples labelled as negative: 375\n",
    "\n",
    "For calculations, we've inputted these numbers in R for you per the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "m1_tp = 601\n",
    "m1_tn = 999\n",
    "m1_fp = 371\n",
    "m1_fn = 29\n",
    "\n",
    "m2_tp = 255\n",
    "m2_tn = 1345\n",
    "m2_fp = 25\n",
    "m2_fn = 375"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q15a.** (6 points) What is the accuracy of Model 1 and Model 2, respectively?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q15b.** (6 points) Of the examples that were *lablled* positive, what proportion are correctly predicted in Model 1? Model 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q15c.** (6 points) Of the examples that are *actually* negative, what proportion are correctly predicted in Model 1? Model 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q15d.** (6 points) Of the examples that are *actually* positive, what proportion are correctly predicted in Model 1? Model 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q15e.** (8 points) Based on the above, are these two models producing equivalent performance? Why or why not? Describe a situation where application of Model 1 would be preferrable to Model 2; and conversely, a situation where application of Model 2 might be preferrable to Model 1. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.1"
  },
  "name": "Online_database_in_class.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
