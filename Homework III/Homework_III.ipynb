{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Set - III"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each Question/subquestion is worth **5 points**, unless indicated otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENCODE: Testing for Enrichment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to learn about possible genetic mechanisms of Alzheimer's using ENCODE data.\n",
    "\n",
    "SNPs associated with this disease can be found in `ALZ_SNPs_hg38.bed`.\n",
    "\n",
    "Choose an ENCODE data set from the ENCODE website that you think may be relevant to the disease (note: feel free to choose a tissue other than brain...there could be other tissues linked to the disease as well). Think both about tissue-type and ENCODE mark. Please do not use DNAse hypersensitivity or RNA-seq datasets. \n",
    "\n",
    "**Hint: it will be easiest if you find a data set with data in the bed file format.**\n",
    "\n",
    "**Note: Make sure the coordinates of the file you pick also use the hg38 reference genome**\n",
    "\n",
    "**Note: PLEASE try to pick a file size that is Less than 1 Gb -- this will make it run faster/Feasibly on CoCalc!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.** (2 points) What dataset did you choose and why? Include the tissue, epigenetic mark tested, and any identifying information, such as the name of the sample."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2:** (5 points) Now, test for significant overlap bewtween the Alzheimer's SNPs and your ENCODE mark. This time, instead of generating fake SNP sets, use the fisher exact test implemented in bedtools (http://bedtools.readthedocs.org/en/latest/content/tools/fisher.html). \n",
    "\n",
    "**NOTE: The fisher tool requires that your data is pre-sorted by chromosome and then by start position. e.g.**\n",
    "\n",
    "```bash\n",
    "$ sort -k1,1 -k2,2n in.bed > in.sorted.bed \n",
    "```\n",
    "    \n",
    "**for BED files, where `in.bed` is your input bed file and `in.sorted.bed` is the name that you want for the sorted output.**\n",
    "\n",
    "This test looks for an association between two classifications. In our case, we are looking for an association between being a SNP in ALZ_SNPs_hg38.bed and being in an interval from your ENCODE data set. Run this test on your datasets. \n",
    "\n",
    "**NOTE: We have provided you a pre-sorted genome file in this directory that you can use for this analysis (human.hg38.genome).**\n",
    "\n",
    "What is the two-tailed p-value? This is the p-value that under the null hypothesis (random chance), the given parameter (probability of overlap) is more extreme than what we observe in our data. Please include your unix commands in the top box and your answer in the bottom box."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "$ "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "The two-tailed p-value is ___________."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3.** (5 points)  Was there a significant association between the disease-associated genetic variants and the ENCODE mark? Explain your findings to the best of your abilities. Are you suprised by the result? If so, why? If not, why not?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENCODE: Finding Active regulatory regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You also know that H3K9me3 is a sign of *repressed* chromatin. Download and unzip the narrowPeak bed file for mouse H3K9me3 data (file **ENCFF234GVB**). Then, using the intersect command and -v flag, count the number of genes from MeAc_genes.bed that do **NOT** also have a H3K9me3 mark. MeAc_genes.bed was generated in the 2nd Encode Module and has been provided in this folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4.** (5 points) Write the bedtools command(s) to do this."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5.** (5 points) How many genes from MeAc_genes.bed do not have a H3K9me3 mark?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "____ genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6.** (5 points) Are you convinced that these genes are truly active genes in embroynic mouse liver? Do you think that there may be some genes in liver_genes.txt that are expressed that we missed? Why or why not? What complexities are we overlooking?\n",
    "\n",
    "*Hint: Think about issues such as where different marks should be located relative to the gene (from the Enhancer paper in the prelab), whether bedtool's window command was the ideal one to use, and cell type heterogeneity*."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Pipelines and Automation of analysis (Rscripts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In module 22, you created an Rscript that you can use for high-throughput analysis of some data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7.** (5 points) Provide a copy of the Rscript that you created in your `H03_Homework-III` directory!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q8.** (5 points) Now, let's unlock the power of automation. We have provided you with 3 data sets (exp1, exp2, exp3):\n",
    "\n",
    "    /data\n",
    "    \n",
    "Using your script, analyze each of the 3 data sets provided and generate outputs!"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q9a** (3 points) In an R code block, read each of the 3 output files you created into R and print the contents to your notebook. \n",
    "\n",
    "Provide your code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "**Q9b** (2 points) Using a **SINGLE** UNIX command, view the contents of all three output files. HINT: the commands `head` and `cat` can display multiple files with only one command - you might need to look up how to do this.\n",
    "\n",
    "Provide your code below:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q10.** (5 points) You'll note that if you had 1000s of experiments to analyze, it would be a real pain to write out the command line for each one -- you have better things to do than that!\n",
    "\n",
    "What could you do to save yourself from needing to do that? How would you modify the code to achieve that? (Provide a general description, but no need to write specific code)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automation / re-analysis Using Jupyter Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Module 23 (Pharmcology), you will have probably noted that you could have tabulated virtually all of the above in excel. \n",
    "\n",
    "However, in a true high-throughput screening assay, you will have **hundreds** of plates to process. That's too much for even one human to do in excel, perfectly! \n",
    "\n",
    "You may also have noticed that through doing this assignment, you have written a 'generic' pipeline to process a single plate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q11.** (5 points) Return to the in-class module. In order to process a different plate, called `plate2`, what would you change in the pipeline you created?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q12.** (5 points) In your module 23 directory, we included data from 6 additional plates. \n",
    "\n",
    "Process each and report here (excluding controls):\n",
    "- the Z prime factor for each plate  \n",
    "- the number of cells that gave lower than a **-4** normalized score, excluding controls, per plate. Note that rather than counting the results on the heatmap, you could `sum()` within the appropriate part of the heatmap table (excluding the controls, of course)\n",
    "\n",
    "To do this, you could change the plate and re-run the markdown, and record the results in the cells below."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Z-factor for plate 2 is: \n",
    "Z-factor for plate 3 is: \n",
    "Z-factor for plate 4 is: \n",
    "Z-factor for plate 5 is: \n",
    "Z-factor for plate 6 is: \n",
    "Z-factor for plate 7 is: "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Number of cells less than -4 for plate 2 is: \n",
    "Number of cells less than -4 for plate 3 is: \n",
    "Number of cells less than -4 for plate 4 is: \n",
    "Number of cells less than -4 for plate 5 is: \n",
    "Number of cells less than -4 for plate 6 is: \n",
    "Number of cells less than -4 for plate 7 is: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice that in these data, you do not actually have any sample names attached to your data, e.g. what genes you actually screened.\n",
    "\n",
    "Imagine that you were provided a file that looked like the following:\n",
    "\n",
    "    sampleid,row,col,plate\n",
    "    87234,C,3,1\n",
    "    7134,C,4,1\n",
    "    ...\n",
    "    81672,P,22,7\n",
    "\n",
    "i.e. a file with 2240 rows (+1 header) where each sampleids was mapped to a corresponding row and column. Note that positive and negative control columns are excluded.\n",
    "\n",
    "**Q13.** (5 points) Imagine that you now wanted to obtain the sampleids (i.e., the gene code id!) from the a set of cells that were of interest, the 'hits' from the screen. \n",
    "\n",
    "For that, imagine that you had a second file which collated all of the cells across all plates which had a normalized Z-score less than -5. e.g., it looked like this:\n",
    "\n",
    "    row,col,plate\n",
    "    C,3,1\n",
    "    D,5,2\n",
    "    P,6,7\n",
    "\n",
    "Describe in words the steps that would allow a computer to print out the sampleids ONLY for the entries listed in this new file. To help you, we have provided the first two steps in the process. You complete the rest!\n",
    "   * Be specific in the details of what you would check for during your look-up.\n",
    "   * Hint: Pretend of you had two sheets of paper, each with your lists, and you had to do this 'by hand'. What would you do, step-by-step?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Step one: Tell the computer to load the sampleid file into memory in R\n",
    "Step two: Tell the computer to load the 'hit' file into memory in R\n",
    "Step three:\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q13 BONUS** (0 points) The following problem is optional, and will not affect your score on this homework in any way. However, if you provide a correct solution, you will get a \"first Dibs\" certificate for an event on the last day of class. *This will have nothing to do with your grade*.\n",
    "\n",
    "Write code in R that implements your solution to Q13. You may use tidyverse. We have provided both files described in the question in the `q13_bonus` directory. Note that this data was randomly generated, and does not match up with data from the Pharmacology module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction measurements and Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q14.** (6 points) In the context of machine learning problems, describe what is meant by the following terms:\n",
    "\n",
    "- Features\n",
    "- Examples\n",
    "- Labels\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Feature: \n",
    "\n",
    "Example:\n",
    "\n",
    "Label: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q15.** Imagine data from two trained models applied to a test set:\n",
    "\n",
    "Model 1:\n",
    "- Correctly labelled true positives examples: 601\n",
    "- Correctly laballed true negatives examples: 999\n",
    "- Actually negative examples labelled as positive: 371\n",
    "- Actually positive examples labelled as negative: 29\n",
    "\n",
    "Model 2:\n",
    "- Correctly labelled true positives examples: 255\n",
    "- Correctly laballed true negatives examples: 1345\n",
    "- Actually negative examples labelled as positive: 25\n",
    "- Actually positive examples labelled as negative: 375\n",
    "\n",
    "For calculations, we've inputted these numbers in R for you per the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "m1_tp = 601\n",
    "m1_tn = 999\n",
    "m1_fp = 371\n",
    "m1_fn = 29\n",
    "\n",
    "m2_tp = 255\n",
    "m2_tn = 1345\n",
    "m2_fp = 25\n",
    "m2_fn = 375"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q15a.** (6 points) What is the accuracy of Model 1 and Model 2, respectively?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q15b.** (6 points) Of the examples that were *lablled* positive, what proportion are correctly predicted in Model 1? Model 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q15c.** (6 points) Of the examples that are *actually* negative, what proportion are correctly predicted in Model 1? Model 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q15d.** (6 points) Of the examples that are *actually* positive, what proportion are correctly predicted in Model 1? Model 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q15e.** (8 points) Based on the above, are these two models producing equivalent performance? Why or why not? Describe a situation where application of Model 1 would be preferrable to Model 2; and conversely, a situation where application of Model 2 might be preferrable to Model 1. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.1"
  },
  "name": "Online_database_in_class.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
